### 英语学习

#### 3. The Programming Interface
```
What functions do we need an operating system to provide applications?
1. Process management. Can a program create an instance of another program? Wait
for it to complete? Stop or resume another running program? Send it an asynchronous
event?
2. Input/output. How do processes communicate with devices attached to the computer
and through them to the physical world? Can processes communicate with each
other?
3. Thread management. Can we create multiple activities or threads that share memory
or other resources within a process? Can we stop and start threads? How do we
synchronize their use of shared data structures?
4. Memory management. Can a process ask for more (or less) memory space? Can it
share the same physical memory region with other processes?
5. File systems and storage. How does a process store the user’s data persistently so
that it can survive machine crashes and disk failures? How does the user name and
organize their data?
6. Networking and distributed systems. How do processes communicate with
processes on other computers? How do processes on different computers coordinate
their actions despite machine crashes and network problems?
7. Graphics and window management. How does a process control pixels on its
portion of the screen? How does a process make use of graphics accelerators?
8. Authentication and security. What permissions does a user or a program have, and
how are these permissions kept up to date? On what basis do we know the user (or
program) is who they say they are?

persistently
美[pɚˈsɪstəntlɪ]
adv. 坚持地；固执地

coordinate
美[ koʊˈɔːrdɪneɪt]
v. (使)协调；搭配

despite
美[dɪˈspaɪt]
prep. 尽管

portion
美[ˈpɔːrʃn]
n. 一部分
```

```
3.1 Process Management

A different approach is to allow user programs to create and manage their own processes.
This has fostered a blizzard of innovation. Today, programs that create and manage
processes include window managers, web servers, web browsers, shell command line
interpreters, source code control systems, databases, compilers, and document
preparation systems. We could go on, but you get the idea. If creating a process is
something a process can do, then anyone can build a new version of any of these
applications, without recompiling the kernel or forcing anyone else to use it.

approach
美[əˈproʊtʃ]
v. 对付，处理

foster
美[ˈfɑːstər]
v. 促进，鼓励

innovation
美[ˌɪnəˈveɪʃn]
n. 改革，创新

interpreter
美[ɪnˈtɜːrprətər]
n. 解释者
```

```
3.1.1 Windows Process Management

Unfortunately, there are quite a few aspects of the process that the parent might like to
control, such as: its privileges, where it sends its input and output, what it should store its
files, what to use as a scheduling priority, and so forth. We cannot trust the child process
itself to set its own privileges and priority, and it would be inconvenient to expect every
application to include code for figuring out its context. So the real interface to
CreateProcess is quite a bit more complicated in practice.

privilege
美[ˈprɪvəlɪdʒ]
n. 特权

inconvenient
美[ˌɪnkənˈvinjənt]
adj. 不方便的；打扰人的

complicated
美[ˈkɑːmplɪkeɪtɪd]
adj. 复杂的
```

```
3.1.2 UNIX Process Management

Further, in both Windows and UNIX, handles are reference counted. Whenever the kernel returns a handle, it bumps a reference counter, and whenever the process releases a handle (or exits), the reference counter is decremented. UNIX fork sets the process ID reference count to two, one for the parent and one for the child. The underlying data structure, the PCB, is reclaimed only when the reference count goes to zero, that is, when both the parent and child terminate.

bump
美[bʌmp]
v. 碰撞；引起

reclaim
美[rɪˈkleɪm]
vt. 回收再利用
```

```
3.2 Input/Output

The Internet has a similar facility to UNIX pipes called TCP (Transmission Control
Protocol). Where UNIX pipes connect processes on the same machine, TCP provides
a bi-directional pipe between two processes running on different machines. In TCP,
data is written as a sequence of bytes on one machine and read out as the same
sequence on the other machine.

facility
美[fəˈsɪləti]
n. 设施

bi-directional
美['bɪdɪr'ekʃənl]
adj. 双流向的

sequence
美[ˈsiːkwəns]
n. [数]数列，序列
```

```
3.3 Case Study: Implementing a Shell

use a pipe to connect two programs together, so that the output of one is the input of
another. This is called a producer-consumer relationship. For example, in the C-compiler, 
the output of the preprocessor is sent to the parser, and the output of the
parser is sent to the code-generator and then to the assembler. In the standard UNIX
shell, a pipe connecting two programs is signified by a “|” symbol, as in: “cpp file.c |
cparse | cgen | as > file.o”. In this case the shell creates four separate child processes,
each connected by pipes to its predecessor and successor. Each of the phases can
run in parallel, with the parent waiting for all of them to finish.

signified
美[ˈsɪɡnəˌfaɪd]
v. 表示…的意思

phase
美[feɪz]
n. 阶段

parallel
美[ˈpærəlel]
adj. 并行的
```

```
3.4 Case Study: Interprocess Communication

Three widely used forms of interprocess communication are:
1. Producer-consumer.
2. Client-server.
3. File system.
```

```
3.4.1 Producer-Consumer Communication

In UNIX, when the producer finishes, it closes its side of the pipe, but there may still be
data queued in the kernel for the consumer. Eventually, the consumer reads the last of the
data, and the read system call will return an “end of file” marker. Thus, to the consumer,
there is no difference between reading from a pipe and reading from a file.

eventually
美[ɪˈventʃuəli]
adv. 最后
```

```
3.4.2 Client-Server Communication

We can take this streamlining even further. On a multicore system, it is possible or even likely that both the client and server each have their own processor. If the kernel sets up a shared memory region accessible to both the client and the server and no other processes, then the client and server can (safely) pass requests and replies back and forth, as fast as the memory system will allow, without ever traversing into the kernel or relinquishing their processors.

streamlining
美['strimlaɪnɪŋ]
n. 流程

traverse
美[ˈtrævɜːrs]
n. 穿越

relinquish
美[rɪˈlɪŋkwɪʃ]
vt. 放弃；让出
```

```
3.5 Operating System Structure

Inside the operating system, there is often quite frequent interaction between these modules:
1. Many parts of the operating system depend on synchronization primitives for
coordinating access to shared data structures with the kernel.
2. The virtual memory system depends on low-level hardware support for address
translation, support that is specific to a particular processor architecture.
3. Both the file system and the virtual memory system share a common pool of blocks of
physical memory. They also both depend on the disk device driver.
4. The file system can depend on the network protocol stack if the disk is physically
located on a different machine.

synchronization
美[ˌsɪŋkrənaɪ'zeɪʃn]
n. 同一时刻

primitive
美[ˈprɪmətɪv]
n. 原语

coordinating
美[ koˈɔrdɪnetɪŋ]
v. 使协调

specific
美[spəˈsɪfɪk]
adj. 明确的；独特的

particular
美[pərˈtɪkjələr]
adj. 特定的；特殊的
```

```
3.5.1 Monolithic Kernels

Internal to a monolithic kernel, the operating system designer is free to develop whatever
interfaces between modules that make sense, and so there is quite a bit of variation from
operating system to operating system in those internal structures. However, two common
themes emerge across systems: to improve portability, almost all modern operating
systems have both a hardware abstraction layer and dynamically loaded device drivers.

internal
美[ɪnˈtɜːrnl]
adj. 内部的

monolithic
美[ˌmɑnəˈlɪθɪk]
adj. 整体的；庞大的

variation
美[ˌveriˈeɪʃn]
n. 变化

emerge
美[iˈmɜːrdʒ]
v. 出现，兴起
```

```
3.5.2 Microkernel

A microkernel design offers considerable benefit to the operating system developer, as it
easier to modularize and debug user-level services than kernel code. Aside from a
potential reliability improvement, however, microkernels offer little in the way of visible
benefit to end users and can slow down overall performance by inserting extra steps
between the application and the services it needs. Thus, in practice, most systems adopt a
hybrid model where some operating system services are run at user-level and some are in
the kernel, depending on the specific tradeoff between code complexity and performance.

considerable
美[kənˈsɪdərəbl]
adj. 相当多的

modularize
美['mɒdʒələˌraɪz]
v. 模块化

potential
美[pəˈtenʃl]
adj. 潜在的

adopt
美[ əˈdɑːpt]
v. 采用

complexity
美[kəmˈpleksəti]
n. 复杂性
```

```
3.6 Summary and Future Directions

Of course, the reality is often quite different. An alternate model is for operating systems to
divide resources among applications and then allow each application to decide for itself
how best to use those resources. One can think of this as a type of federalism. If both the
operating system and applications are governments doing their own resource allocation,
they are likely to get in each other’s way if they are not careful. As a simple example,
consider how a garbage collector works; it assumes it has a fixed amount of memory to
manage. However, as other applications start or stop, it can gain or lose memory, and if the
operating system does this reallocation transparently, the garbage collector has no hope of
adapting. We will see examples of this same design pattern in many different areas of
operating system design.

reality
美[riˈæləti]
n. 现实

divide
美[dɪˈvaɪd]
v. 分开；分配

federalism
英['fedərəlɪzəm]
n. 联邦政治
```

```
8. Address Translation

Chapter roadmap:
1. Address Translation Concept. We start by providing a conceptual framework for
understanding both hardware and software address translation. (Section 8.1)
2. Flexible Address Translation. We focus first on hardware address translation; we
ask how can we design the hardware to provide maximum flexibility to the operating
system kernel? (Section 8.2)
3. Efficient Address Translation. The solutions we present will seem flexible but terribly
slow. We next discuss mechanisms that make address translation much more efficient,
without sacrificing flexibility. (Section 8.3)
4. Software Protection. Increasingly, software compilers and runtime interpreters are
using address translation techniques to implement operating system functionality. 
What changes when the translation is in software rather than in hardware?

flexible
美[ˈfleksəbl]
adj. 灵活的

present
美[ˈpreznt]
v. 展示，呈现

mechanism
美[ˈmekənɪzəm]
n. 机制

sacrifice
美[ˈsækrɪfaɪs]
v. 牺牲
```

```
8.1 Address Translation Concept

Today, we still have something similar. Complex programs often have multiple files, each of which can be compiled independently and then linked together to form the executable image. When the compiler generates the machine instructions for a single file, it cannot know where in the executable this particular file will go. Instead, the compiler generates a symbol table at the beginning of each compiled file, indicating which values will need to be modified when the individual files are assembled together.

assemble
美[əˈsembl]
v. 聚集
```

```
8.2 Towards Flexible Address Translation

Base and bounds translation is both simple and fast, but it lacks many of the features
needed to support modern programs. Base and bounds translation supports only coarse-grained 
protection at the level of the entire process; it is not possible to prevent a program
from overwriting its own code, for example. It is also difficult to share regions of memory
between two processes. Since the memory for a process needs to be contiguous,
supporting dynamic memory regions, such as for heaps, thread stacks, or memory mapped
files, becomes difficult to impossible.

bound
美[baʊnd]
n. 界限，限制

coarse
美[kɔːrs]
adj. 粗糙的
```

```
8.2.1 Segmented Memory

However we choose to place new segments, as more memory becomes allocated, the
operating system may reach a point where there is enough free space for a new segment,
but the free space is not contiguous. This is called external fragmentation. The operating
system is free to compact memory to make room without affecting applications, because
virtual addresses are unchanged when we relocate a segment in physical memory. Even
so, compaction can be costly in terms of processor overhead: a typical server configuration
would take roughly a second to compact its memory.

contiguous
美[kənˈtɪɡjuəs]
adj. 邻近的

external
美[ɪkˈstɜːrnl]
n. 外部

fragmentation
英[ˌfræɡmen'teɪʃn]
n. 碎片

compact
美[ˈkɑːmpækt]
v. 把…压实
```

```
8.2.2 Paged Memory

A downside of paging is that while the management of physical memory becomes simpler,
the management of the virtual address space becomes more challenging. Compilers
typically expect the execution stack to be contiguous (in virtual addresses) and of arbitrary
size; each new procedure call assumes the memory for the stack is available. Likewise, the
runtime library for dynamic memory allocation typically expects a contiguous heap. In a
single-threaded process, we can place the stack and heap at opposite ends of the virtual
address space, and have them grow towards each other, as shown in Figure 8.5. However,
with multiple threads per process, we need multiple thread stacks, each with room to grow.

downside
美[ˈdaʊnsaɪd]
n. 负面

arbitrary
美[ˈɑːrbɪtreri]
adj. 任意的
```

```
8.2.3 Multi-Level Translation

For encoding efficiency, the segment register is often implicit as part of the instruction. For
example, the x86 stack instructions such as push and pop assume the stack segment (the
index stored in the stack segment register), branch instructions assume the code segment
(the index stored in the code segment register), and so forth. As an optimization, whenever
the x86 initializes a code, stack, or data segment register it also reads the GDT entry (that
is, the top-level page table pointer and access permissions) into the processor, so the
processor can go directly to the page table on each reference.

implicit
美[ɪmˈplɪsɪt]
adj. 不言明的
```

```
8.2.4 Portability

In software view, linux models the operating system’s internal address translation data structures after the
x86 architecture of segments plus multi-level page tables. This has made porting Linux to
new x86 architectures relatively easy, but porting Linux to other architectures somewhat
more difficult e.g. Mac OS.
In hardware view, consisting of three parts:
1. List of memory objects.
2. Virtual to physical translation.
3. Physical to virtual translation.

relatively
美[ˈrelətɪvli]
adv. 相对地
```

```
8.3 Towards Efficient Address Translation

For this, we will use a cache, a copy of some data that can be accessed more quickly than
the original. This section concerns how we might use caches to improve translation
performance. Caches are widely used in computer architecture, operating systems,
distributed systems, and many other systems; in the next chapter, we discuss more
generally when caches work and when they do not. For now, however, our focus is just on
the use of caches for reducing the overhead of address translation. There is a reason for
this: the very first hardware caches were used to improve translation performance.
```

```
8.3.1 Translation Lookaside Buffers

Software-loaded TLB. If the TLB is effective at amortizing the cost of doing a full address translation across many memory references, we can ask a radical question: do we need hardware multi-level page table lookup on a TLB miss? This is the concept behind a software-loaded TLB. A TLB hit works as before, as a fast path. On a TLB miss, instead of doing hardware address translation, the processor traps to the operating system kernel. In the trap handler, the kernel is responsible for doing the address lookup, loading the TLB with the new translation, and restarting the application.

amortize
美[ˈæmərtaɪz]
vt. 分期偿还

radical
美[ˈrædɪkl]
adj. 根本的，基本的

consult
美[kənˈsʌlt]
v. 咨询；商量
```

```
8.3.2 Superpages

A common use of superpages is to map the frame buffer for the computer display. When
redrawing the screen, the processor may touch every pixel; with a high-resolution display,
this can involve stepping through many megabytes of memory. If each TLB entry maps a 4
KB page, even a large on-chip TLB with 256 entries would only be able to contain
mappings for 1 MB of the frame buffer at the same time. Thus, the TLB would need to
repeatedly do page table lookups to pull in new TLB entries as it steps through memory. An
even worse case occurs when drawing a vertical line. The frame buffer is a two-dimensional 
array in row-major order, so that each horizontal line of pixels is on a separate
page. Thus, modifying each separate pixel in a vertical line would require loading a
separate TLB entry! With superpages, the entire frame buffer can be mapped with a single
TLB entry, leaving more room for the other pages needed by the application.

vertical
美[ˈvɜːrtɪkl]
adj. 垂直的

horizontal
美[ˌhɔːrɪˈzɑːntl]
adj. 水平的
```

```
8.3.3 TLB Consistency

TLB shootdown. On a multiprocessor, there is a further complication. Any processor
in the system may have a cached copy of a translation in its TLB. Thus, to be safe and
correct, whenever a page table entry is modified, the corresponding entry in every
processor’s TLB has to be discarded before the change will take effect. Typically, only
the current processor can invalidate its own TLB, so removing the entry from all
processors on the system requires that the operating system interrupt each processor
and request that it remove the entry from its TLB.
This heavyweight operation has its own name: it is a TLB shootdown, illustrated in
Figure 8.15. The operating system first modifies the page table, then sends a TLB
shootdown request to all of the other processors. Once another processor has
ensured that its TLB has been cleaned of any old entries, that processor can resume.
The original processor can continue only when all of the processors have
acknowledged removing the old entry from their TLB. Since the overhead of a TLB
shootdown increases linearly with the number of processors on the system, many
operating systems batch TLB shootdown requests, to reduce the frequency of
interprocess interrupts at some increased cost in latency to complete the shootdown.

corresponding
美[ˌkɔːrəˈspɑːndɪŋ]
adj. 相应的

invalidate
美[ɪnˈvælɪdeɪt]
vt. 使无效

heavyweight
美[ˈheviweɪt]
n. 重量级拳击

linearly
美[ ˈlɪniərli]
adv. 直线地

frequency
美[ˈfriːkwənsi]
n. 频繁性

latency
美[ˈletnsi]
n. 潜伏；潜在因素
```

```
8.3.4 Virtually Addressed Caches

A further issue is aliasing. Many operating systems allow processes sharing memory to
use different virtual addresses to refer to the same memory location. This is called a
memory address alias. Each process will have its own TLB entry for that memory, and the
virtual cache may store a copy of the memory for each process. The problem occurs when
one process modifies its copy; how does the system know to update the other copy?
The most common solution to this issue is to store the physical address along with the
virtual address in the virtual cache. In parallel with the virtual cache lookup, the TLB is
consulted to generate the physical address and page permissions. On a store instruction
modifying data in the virtual cache, the system can do a reverse lookup to find all the
entries that match the same physical address, to allow it to update those entries.

alias
英[ˈeɪliəs]
n. 别名

parallel
美[ˈpærəlel]
adj. 并行的
```

```
8.3.5 Physically Addressed Caches

Together, these physically addressed caches serve a dual purpose:
1. Faster memory references. An on-chip physically addressed cache will have a
lookup latency that is ten times (2nd level) or three times (3rd level) faster than main
memory.
2. Faster TLB misses. In the event of a TLB miss, the hardware will generate a
sequence of lookups through its multiple levels of page tables. Because the page
tables are stored in physical memory, they can be cached. Thus, even a TLB miss and
page table lookup may be handled entirely on chip.

dual
美[ˈduːəl]
adj. 两部分的

latency
美[ˈletnsi]
n. 潜伏；潜在因素
```

```
8.4 Software Protection

Why do we need to implement protection in software?
1. Simplify hardware. 
2. Application-level protection.
3. Protection inside the kernel.
4. Portable security.
```

```
8.4.1 Single Language Operating Systems

Another example of the same approach is the use of JavaScript in modern web browsers,
illustrated in Figure 8.20. A JavaScript program customizes the user interface and
presentation of a web site; it is provided by the web site, but it executes on the client
machine inside the browser. As a result, the browser execution environment for JavaScript
must prevent malicious JavaScript programs from taking control over the browser and
possibly the rest of the client machine. Since JavaScript programs tend to be relatively
short, they are often interpreted; JavaScript can also call into a predefined set of library
routines. If a JavaScript program attempts to call a procedure that does not exist or
reference arbitrary memory locations, the interpreter will cause a runtime exception and
stop the program before any harm can be done.

malicious
美[məˈlɪʃəs]
adj. 恶意的

arbitrary
美[ˈɑːrbɪtreri]
adj. 武断的，任意的
```

```
8.4.2 Language-Independent Software Fault Isolation

What happens if we are running on top of an operating system that does not support a virtual machine? We can still emulate a virtual machine by modifying the machine code of the guest operating system kernel. For example, we can convert instructions to enable and disable interrupts to a no op. We can convert an instruction to start executing a user program to take the contents of the application memory, re-write those contents into a user-level sandbox, and start it executing. From the perspective of the guest kernel, the application program execution looks normal; it is the sandbox that keeps the application program from corrupting kernel’s data structures and passes control to the guest kernel when the application makes a system call. 
Because of the widespread use of virtual machines, some hardware architectures have begun to add support for directly executing guest operating systems in user-mode without kernel support. We will return to this issue in a later chapter, as it is closely related to the topic of stackable virtual machines: how do we manipulate page tables to handle the case where the guest operating system is itself a virtual machine monitor running a virtual machine.

no op
空操作

manipulate
美[məˈnɪpjuleɪt]
vt. 操作
```

```
8.4.3 Sandboxes Via Intermediate Code

The intermediate representation can be thought of as a virtual machine, with a simpler
instruction set. From the compiler perspective, it is as easy to generate code for the virtual
machine as it would be to go directly to x86 or ARM instructions. From the sandbox
perspective though, using a virtual machine as the intermediate representation is much
simpler. The intermediate code can include annotations as to which pointers can be proven
to be safe and which must be checked before use. For example, pointers in a C program
would require runtime checks while the memory references in a Java program may be able
to be statically proven as safe from the structure of the code.

intermediate
美[ˌɪntərˈmiːdiət]
adj. 中间的

annotation
美[ˌænə'teɪʃn]
n. 注释
```

```
8.5 Summary and Future Directions

User-level sandboxes. Applications like browsers that run untrusted code are
becoming increasingly prevalent. Operating systems have only recently begun to
recognize the need to support these types of applications. Software protection has
become common, both at the language level with JavaScript, and in the runtime
system with Native Client and Application Domains. As these technologies become
more widely used, it seems likely we may direct hardware support for application-level
protection — to allow each application to set up its own protected execution
environment, but enforced in hardware. If so, we may come to think of many
applications as having their own embedded operating system, and the underlying
operating system kernel as mediating between these operating systems.

prevalent
美[ˈprevələnt]
adj. 流行的

enforce
美[ɪnˈfɔːrs]
v. 强制执行

embedded
美[ɪm'bedɪd]
adj. 植入的

mediating
英['miːdɪeɪtɪŋ]
v. 调停，调解
```

```
9. Caching and Virtual Memory

Regardless of the context, all caches face three design challenges:
1. Locating the cached copy. Because caches are designed to improve performance, a
key question is often how to quickly determine whether the cache contains the needed
data or not. Because the processor consults at least one hardware cache on every
instruction, hardware caches in particular are organized for efficient lookup.
2. Replacement policy. Most caches have physical limits on how many items they can
store; when new data arrives in the cache, the system must decide which data is most
valuable to keep in the cache and which can be replaced. Because of the high relative
latency of fetching data from disk, operating systems and applications have focused
more attention on the choice of replacement policy.
3. Coherence. How do we detect, and repair, when a cached copy becomes out of date?
This question, cache coherence, is central to the design of multiprocessor and
distributed systems. Despite being very important, cache coherence beyond the scope
of this version of the textbook. Instead, we focus on the first two of these issues.

latency
美[ˈletnsi]
n. 潜伏；潜在因素

coherence
美[koʊˈhɪrəns]
n. 一致性

central
美[ˈsentrəl]
adj. 中心的

despite
美[dɪˈspaɪt]
prep. 尽管
```

```
9.1 Cache Concept

The behavior of a cache on a write operation is shown in Figure 9.2. The operation is a bit
more complex, but the latency of a write operation is easier to understand. Most systems
buffer writes. As long as there is room in the buffer, the computation can continue
immediately while the data is transferred into the cache and to memory in the background.
(There are certain restrictions on the use of write buffers in a multiprocessor system, so for
this chapter, we are simplifying matters to some degree.) Subsequent read requests must
check both the write buffer and the cache — returning data from the write buffer if it is the
latest copy.

We first discuss the part of the equation that deals with the latency of a cache hit and a
cache miss: how long does it take to access different types of memory? We caution,
however, that the issues that affect the likelihood of a cache hit or miss are just as
important to the overall memory latency. In particular, we will show that application
characteristics are often the limiting factor to good cache performance.

computation
美[ˌkɑmpjuˈteɪʃn]
n. 计算

restriction
美[rɪˈstrɪkʃn]
n. 限制

subsequent
美[ˈsʌbsɪkwənt]
adj. 后来的；随后的

equation
美[ɪˈkweɪʒn]
n. 等式，方程式

latency
美[ˈletnsi]
n. 潜伏；潜在因素

likelihood
美[ˈlaɪklihʊd]
n. 可能，可能性

characteristic
美[ˌkærəktəˈrɪstɪk]
n. 特色；特点
```

```
9.2 Memory Hierarchy

However, there are reasons to be skeptical. Even with temporal and spatial locality, there
are thirteen orders of magnitude difference in storage capacity from the first level cache to
the stored data of a typical data center; this is the equivalent of the smallest visible dot on
this page versus those dots scattered across the pages of a million textbooks just like this
one. How can a cache be effective if it can store only a tiny amount of the data that could
be stored?

The cost of a cache miss can also be high. There are eight orders of magnitude difference
between the latency of the first-level cache and a remote data center disk; that is
equivalent to the difference between the shortest latency a human can perceive — roughly
one hundred milliseconds — versus one year. How can a cache be effective if the cost of a
cache miss is enormous compared to a cache hit?

skeptical
美[ˈskeptɪkl]
adj. 怀疑性的

scattered
美[ˈskætərd]
adj. 分散的

magnitude
美[ˈmæɡnɪtuːd]
n. 巨大

enormous
美[ɪˈnɔːrməs]
adj. 巨大的
```

```
9.3 When Caches Work and When They Do Not

Cache hit rate as a function of cache size for a million instruction run of a C compiler. The hit 
rate vs. cache size graph has a similar shape for many programs. The knee of the curve is called the
working set of the program.

similar
美[ˈsɪmələr]
adj. 类似的

curve
美[kɜːrv]
n. 曲线
```

```
9.3.1 Working Set Model

Most programs will have an inflection point, or knee of the curve, where a critical mass of
program data can just barely fit in the cache. This critical mass is called the program’s
working set. As long as the working set can fit in the cache, most references will be a
cache hit, and application performance will be good.

inflection
美[ɪnˈflɛkʃən]
n. 转调

knee
美[niː]
n. 膝部

curve
美[kɜːrv]
n. 曲线

critical
美[ˈkrɪtɪkl]
adj. 关键的
```